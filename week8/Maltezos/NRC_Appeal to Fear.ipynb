{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_arg = pd.read_excel('cnn_arg_only_clean.xlsx')\n",
    "cnn_conc = pd.read_excel('cnn_conclusion_only_clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "cnn_arg.loc[:,'argum'] = cnn_arg.loc[:,'argum'].apply(lambda x: literal_eval(x))\n",
    "cnn_arg.loc[:,'polarity_argum'] = cnn_arg.loc[:,'polarity_argum'].apply(lambda x: literal_eval(x))\n",
    "cnn_arg.loc[:,'subjectivity_argum'] = cnn_arg.loc[:,'subjectivity_argum'].apply(lambda x: literal_eval(x))\n",
    "cnn_arg.loc[:,'argum_pos'] = cnn_arg.loc[:,'argum_pos'].apply(lambda x: literal_eval(x))\n",
    "cnn_arg.loc[:,'argum_neg'] = cnn_arg.loc[:,'argum_neg'].apply(lambda x: literal_eval(x))\n",
    "cnn_arg.loc[:,'argum_neu'] = cnn_arg.loc[:,'argum_neu'].apply(lambda x: literal_eval(x))\n",
    "cnn_arg.loc[:,'argum_compound'] = cnn_arg.loc[:,'argum_compound'].apply(lambda x: literal_eval(x))\n",
    "\n",
    "cnn_conc.loc[:,'conclusion'] = cnn_conc.loc[:,'conclusion'].apply(lambda x: literal_eval(x))\n",
    "cnn_conc.loc[:,'polarity_conclusion'] = cnn_conc.loc[:,'polarity_conclusion'].apply(lambda x: literal_eval(x))\n",
    "cnn_conc.loc[:,'subjectivity_conclusion'] = cnn_conc.loc[:,'subjectivity_conclusion'].apply(lambda x: literal_eval(x))\n",
    "cnn_conc.loc[:,'conclusion_pos'] = cnn_conc.loc[:,'conclusion_pos'].apply(lambda x: literal_eval(x))\n",
    "cnn_conc.loc[:,'conclusion_neg'] = cnn_conc.loc[:,'conclusion_neg'].apply(lambda x: literal_eval(x))\n",
    "cnn_conc.loc[:,'conclusion_neu'] = cnn_conc.loc[:,'conclusion_neu'].apply(lambda x: literal_eval(x))\n",
    "cnn_conc.loc[:,'conclusion_compound'] = cnn_conc.loc[:,'conclusion_compound'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argum_pos</th>\n",
       "      <th>argum_neg</th>\n",
       "      <th>argum_neu</th>\n",
       "      <th>argum_compound</th>\n",
       "      <th>polarity_argum</th>\n",
       "      <th>subjectivity_argum</th>\n",
       "      <th>text_id</th>\n",
       "      <th>argum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[0.077]</td>\n",
       "      <td>[0.215]</td>\n",
       "      <td>[0.707]</td>\n",
       "      <td>[-0.5106]</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>[0.7]</td>\n",
       "      <td>4</td>\n",
       "      <td>[he said he is \"innocent of all charges and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>7</td>\n",
       "      <td>[so in 1997, gebre returned to ethiopia with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.045]</td>\n",
       "      <td>[0.955]</td>\n",
       "      <td>[-0.2411]</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>9</td>\n",
       "      <td>['a full-blown dictatorship'  dss officials sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  argum_pos argum_neg argum_neu argum_compound polarity_argum  \\\n",
       "0   [0.077]   [0.215]   [0.707]      [-0.5106]          [0.5]   \n",
       "1     [0.0]     [0.0]     [1.0]          [0.0]          [0.0]   \n",
       "2     [0.0]   [0.045]   [0.955]      [-0.2411]          [0.5]   \n",
       "\n",
       "  subjectivity_argum  text_id  \\\n",
       "0              [0.7]        4   \n",
       "1              [0.0]        7   \n",
       "2              [0.5]        9   \n",
       "\n",
       "                                               argum  \n",
       "0  [he said he is \"innocent of all charges and th...  \n",
       "1  [so in 1997, gebre returned to ethiopia with a...  \n",
       "2  ['a full-blown dictatorship'  dss officials sa...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_arg.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['after the story broke in the media, osagie faced a university panel investigating the allegations on the tape and is awaiting its findings so she can receive her certificate.',\n",
       " 'student speaks out  in her only interview since the audio was leaked online, osagie, 23, told cnn she had developed a mentor-mentee relationship with the professor after she helped him edit his book.',\n",
       " \"her lawyer, abiola akiyode-afolabi, told cnn more victims have contacted her with allegations about the same professor since hearing about osagie's case.\",\n",
       " 'â€” remi sonaiya (@oluremisonaiya) april 9, 2018  the practice thrives because students do not come forward with these allegations and also because they do not trust their institutions to handle such matters with discretion, she added.',\n",
       " 'but the relationship soon made her uncomfortable because he started to make sexual advances towards her, she said.',\n",
       " '\"this is because of the caliber of the lecturer involved,\" he added.',\n",
       " 'so, i decided to record our next conversation,\" she added.',\n",
       " \"faced with this stark choice, osagie says she knew no one would believe her word against the lecturer's, so she recorded one of their conversations using a cell phone app.\",\n",
       " \"hashtag campaign reflects outrage  since osagie's recording went viral, many nigerians have led calls for universities to do more to protect students from sexual harassment.\",\n",
       " 'osagie believes he deliberately gave her low marks so she would agree to sleep with him to raise them, she said.',\n",
       " 'backlash on social media  osagie says she has faced severe backlash since the university made her identity public when it released a statement.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_arg['argum'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>emotion</th>\n",
       "      <th>word</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>aback</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>abacus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>abandon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "emotion       word  anger  anticipation  disgust  fear  joy  negative  \\\n",
       "0              NaN      0             0        0     0    0         0   \n",
       "1            aback      0             0        0     0    0         0   \n",
       "2           abacus      0             0        0     0    0         0   \n",
       "3          abandon      0             0        0     1    0         1   \n",
       "4        abandoned      1             0        0     1    0         1   \n",
       "\n",
       "emotion  positive  sadness  surprise  trust  \n",
       "0               0        0         0      0  \n",
       "1               0        0         0      0  \n",
       "2               0        0         0      1  \n",
       "3               0        1         0      0  \n",
       "4               0        1         0      0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"NRC-emotion-lexicon-wordlevel-alphabetized-v0.92.txt\"\n",
    "emolex_df = pd.read_csv(filepath,  names=[\"word\", \"emotion\", \"association\"], skiprows=45, sep='\\t')\n",
    "emolex_df = emolex_df.pivot(index='word', columns='emotion', values='association').reset_index()\n",
    "emolex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of fear words\n",
    "fear_words = emolex_df[emolex_df.fear == 1]['word']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# tuning the vectorizer parameters\n",
    "vectorizer = TfidfVectorizer(vocabulary=fear_words,use_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fear(sent):\n",
    "    vectorizer = TfidfVectorizer(vocabulary=fear_words,use_idf=False)\n",
    "    i= vectorizer.fit_transform(sent)\n",
    "    x= i.toarray()\n",
    "    return(x.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_arg['fear'] = cnn_arg.argum.apply(get_fear)\n",
    "cnn_conc['fear'] = cnn_conc.conclusion.apply(get_fear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_fear(x):\n",
    "    for i in x:\n",
    "        i.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_arg['total_fear'] = cnn_arg.fear.apply(sum)\n",
    "cnn_conc['total_fear'] = cnn_conc.fear.apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fearless= pd.DataFrame()\n",
    "\n",
    "fearless[['appeal_to_fear','fear_indicator','text_id']] = cnn_arg[['argum','total_fear','text_id']]\n",
    "\n",
    "cnn_arg.drop(columns=['fear','total_fear'],inplace=True)\n",
    "\n",
    "# creating a limit / statistical approach\n",
    "differ = (fearless.fear_indicator.mean() + (fearless.fear_indicator.std()))*2\n",
    "\n",
    "fear_index = fearless[fearless['fear_indicator'].apply(lambda x: x < differ)].index\n",
    "\n",
    "fear_fallacy= fearless.drop(fear_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appeal_to_fear</th>\n",
       "      <th>fear_indicator</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>[those five demands are: withdraw the extradit...</td>\n",
       "      <td>10.934636</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>[the officer fired the gun because he believed...</td>\n",
       "      <td>12.715799</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>[but scientists have since found dna evidence ...</td>\n",
       "      <td>8.511308</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>[their aim is to make visible the victims of \"...</td>\n",
       "      <td>9.974691</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>[they give them a bag of food and people sell ...</td>\n",
       "      <td>9.009968</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>[when cnn approached a number of reputable aid...</td>\n",
       "      <td>9.285472</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>[here's why it's legal  birth of a cult brand ...</td>\n",
       "      <td>8.242641</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>[cartoonists, get arrested, put in jail everyw...</td>\n",
       "      <td>10.242641</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>[below the photo is written: \"because one holo...</td>\n",
       "      <td>12.242641</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>[over the years, some who had these surgeries ...</td>\n",
       "      <td>9.828427</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>[\"because all it took me was basically someone...</td>\n",
       "      <td>9.560478</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>['...now, we're winning cases, because they re...</td>\n",
       "      <td>18.242641</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        appeal_to_fear  fear_indicator  \\\n",
       "23   [those five demands are: withdraw the extradit...       10.934636   \n",
       "25   [the officer fired the gun because he believed...       12.715799   \n",
       "26   [but scientists have since found dna evidence ...        8.511308   \n",
       "52   [their aim is to make visible the victims of \"...        9.974691   \n",
       "82   [they give them a bag of food and people sell ...        9.009968   \n",
       "83   [when cnn approached a number of reputable aid...        9.285472   \n",
       "123  [here's why it's legal  birth of a cult brand ...        8.242641   \n",
       "124  [cartoonists, get arrested, put in jail everyw...       10.242641   \n",
       "153  [below the photo is written: \"because one holo...       12.242641   \n",
       "154  [over the years, some who had these surgeries ...        9.828427   \n",
       "199  [\"because all it took me was basically someone...        9.560478   \n",
       "302  ['...now, we're winning cases, because they re...       18.242641   \n",
       "\n",
       "     text_id  \n",
       "23        37  \n",
       "25        41  \n",
       "26        42  \n",
       "52        85  \n",
       "82       125  \n",
       "83       126  \n",
       "123      183  \n",
       "124      184  \n",
       "153      229  \n",
       "154      230  \n",
       "199      295  \n",
       "302      443  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what we got\n",
    "fear_fallacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"but scientists have since found dna evidence that the plague could have existed much further back than previously thought -- there's evidence it existed in europe some 5,000 years ago  and the idea that the second pandemic, the black death, could have started in china is unlikely, black said.\",\n",
       " \"so mao put in place a number of measures to control the country's rampant disease.\",\n",
       " \"but that only led to another question: if the disease wasn't genetically different, then why was the second pandemic so deadly?\",\n",
       " '\"it\\'s so central to western identity,\" he said.',\n",
       " \"yunnan was hit by another breakout between 1986 and 2005 , and another case was diagnosed in yunnan in 2016.  why we're so fascinated by the plague  centuries on from the black death, people around the world continue to be transfixed by the plague in a way they're not by other diseases.\",\n",
       " 'chinese cultural revolution poster about the so-called four pests: mosquitoes, rats, flies and sparrows.',\n",
       " '\"it\\'s part of our past, where something like malaria, which is so much more devastating in the last century, it doesn\\'t interest us.\"']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qualititive inspection\n",
    "fear_fallacy['appeal_to_fear'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # saving the output\n",
    "# fear_fallacy.to_excel('fear/appeal_to_fear_fallacy.xlsx',index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
