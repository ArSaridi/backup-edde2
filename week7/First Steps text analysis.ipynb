{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Μικρή εισαγωγή στην ανάλυση κειμένου!\n",
    "\n",
    "## Θα ξεκινήσουμε να αναλύουμε κείμενα και θα χρησιμοποιήσουμε τις παρακάτω βιβλιοθήκες, για τις οποίες μπορείτε να μάθετε περισσότερα αν επισκεφθείτε τις ιστοσελίδες τους.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob: \"Simplified text processing\"\n",
    "\n",
    "https://textblob.readthedocs.io/en/dev/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy: \"Industrial-Strength Natural Language Processing\"\n",
    "\n",
    "https://spacy.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn: \"Machine Learning in Python\"\n",
    "\n",
    "http://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Toolkit (NLTK): \"A leading platform for building Python programs to work with human language data\"\n",
    "\n",
    "http://www.nltk.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ας πειραματιστούμε με την ανάλυση συναισθήματος"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #για Επεξεργασία φυσικής γλώσσας Natural Language Toolkit\n",
    "import pandas #DataFrames\n",
    "import matplotlib.pyplot as plt #Για γραφικά\n",
    "import wordcloud #Για word clouds\n",
    "import numpy as np \n",
    "import scipy #Για διαφορές και αποστάσεις\n",
    "import seaborn as sns #κάνει τα γραφήματα (plot) πιο όμορφα\n",
    "import sklearn.manifold #Για manifold plot\n",
    "from nltk.corpus import stopwords #Για stopwords\n",
    "import json #Για API responses\n",
    "import urllib.parse #Για ένωση urls\n",
    "\n",
    "#Για να εμφανίζονται τα γραφήματα\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.5, subjectivity=0.6)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(\"I love driving the car.\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.22777777777777777, subjectivity=0.6861111111111112)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = '''I am very disappointed in China. Our foolish past leaders \n",
    "have allowed them to make hundreds of billions of dollars a year in trade, yet\n",
    "they do NOTHING for us with North Korea, just talk. We will no longer allow this\n",
    "to continue. China could easily solve this problem!'''\n",
    "\n",
    "TextBlob(tweet).sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μπορείτε να διαβάσετε το [documentation](https://textblob.readthedocs.io/en/dev/classifiers.html) για περισσότερες πληροφορίες, αλλά εμείς θα μάθουμε περισσότερα για την ανάλυση συναισθήματος παρακάτω."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Μέτρημα λέξεων με το `.count`\n",
    "\n",
    "\n",
    "Για να ξεκινήσουμε την ανάλυση πρώτα μετράμε πόσες φορές εμφανίζεται κάθε λέξη στο κείμενο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"I tried to fish for fish but I didn't catch any fish\".count(\"fish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'fish',\n",
       " 'for',\n",
       " 'fish',\n",
       " 'but',\n",
       " 'I',\n",
       " \"didn't\",\n",
       " 'catch',\n",
       " 'any',\n",
       " 'fish']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_sentence = \"I tried to fish for fish but I didn't catch any fish\"\n",
    "fish_sentence.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_sentence = \"I tried to fish for fish but I didn't catch any fish\"\n",
    "fish_list = fish_sentence.split(\" \")\n",
    "fish_list.count(\"fish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toucan_sentence = \"The canny toucan can't recant about the pelican's scant canteloupe\"\n",
    "toucan_list = toucan_sentence.split(\" \")\n",
    "toucan_list.count(\"can\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tο μέτρημα των λέξεων είναι αρκετά απλό και μπορεί να γίνει σε παραγράφους και ολόκληρα βιβλία. \n",
    "\n",
    "Το πρόβλημα που υπάρχει είναι ότι για παράδειγμα η λέξη can δεν θα μετρηθεί μόνο μία φορά στο παραπάνω παράδειγμα, αλλά όσες φορές εμφανίζεται ακόμα και μέσα σε λέξεις.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"The canny toucan can't recant about the pelican's scant canteloupe\".count(\"can\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η πρόταση έχει `\"can\"` περισσότερες από μία φορές, οπότε πρέπει να λύσουε αυτό το πρόβλημα και να δοκιμάσουμε κάτι πιο αποτελεσματικό."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Τokenization\n",
    "# Φιλτράρισμα και ομαλοποίηση  του κειμένου\n",
    "\n",
    "Για να αρχίσουμε να συγκρίνουμε τα διαφορετικά κείμενα πρέπει πρώτα να ομαλοποιήσουμε το κείμενο και να φιλτράρουμε αυτά στα οποία στην συνέχεια θα επικεντρωθούμε. Αρχικά, θα κάνουμε όλα τα κεφαλαία, μικρά και θα πετάξουμε τα tokens που δεν είναι λέξεις. Στην συνέχεια, θα αφαιρέσουμε τα 'stop words', θα κάνουμε stem τις λέξεις που θα μείνουν για να φύγουν οι καταλήξεις των λέξεων που δεν μας χρειάζονται (suffixes), ή θα κάνουμε λημματισμό (lemmatize) τα tokens μέσω ένος έξυπνου αλγορίθμου που θα αντιλαμβάνεται τις διαφορετικές μορφές μιας ίδιας λέξης (π.χ. χρησιμοποιώντας έναν stemmer και ένα λεξικό). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fish_sentence = \"I tried to fish for fish but I didn't catch any fish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fish_sentence = \"I tried to fish for fish but I didn't catch any fish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toucan_sentence = \"The canny toucan can't recant the pelican's scant canteloupe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βελτίωση του tokenization\n",
    "\n",
    "Μπορούμε να καθαρίζουμε τα κενά και να μετράμε λέξεις, αλλά με τα κεφαλαία και τα σημεία στίξης υπάρχουν αρκετά προβλήματα. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dinner', 'was', 'great', 'tonight,', 'I', 'enjoyed', 'the', 'potatoes.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinner_sentence = \"Dinner was great tonight, I enjoyed the potatoes.\"\n",
    "dinner_list = dinner_sentence.split(\" \")\n",
    "dinner_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Πόσες φορές εμφανίστηκε η λέξη 'dinner'?\n",
    "dinner_list.count(\"dinner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Πόσες φορές εμφανίστηκε η λέξη 'potatoes'?\n",
    "dinner_list.count(\"potatoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dinner', 'was', 'great', 'tonight,', 'i', 'enjoyed', 'the', 'potatoes', '']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinner_sentence = \"Dinner was great tonight, I enjoyed the potatoes.\"\n",
    "dinner_sentence = dinner_sentence.lower().replace(\".\", \" \")\n",
    "dinner_list = dinner_sentence.split(\" \")\n",
    "dinner_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinner_list.count(\"dinner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinner_list.count(\"potatoes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing με το TextBlob\n",
    "\n",
    "Το TextBlob είναι εύχρηστο, αλλά όχι τόσο πλήρες όσο το spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "dangerous\n",
      "cats\n",
      "ran\n",
      "dangerously\n",
      "toward\n",
      "dangers\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "blob = TextBlob(\"The dangerous cats ran dangerously toward dangers.\")\n",
    "\n",
    "for token in blob.tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "dangerous\n",
      "cats\n",
      "ran\n",
      "dangerously\n",
      "toward\n",
      "dangers\n"
     ]
    }
   ],
   "source": [
    "for word in blob.words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Βλέπετε ότι διατηρεί τις φράσεις όταν χρησιμοποιείτε το`.tokens`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing με το spaCy\n",
    "\n",
    "Το spaCy μπορεί να κάνει τα πάντα, αλλά είναι πιο δύσκολο από το TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[The, dangerous, cats, ran, dangerously, toward, dangers]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"The dangerous cats ran dangerously toward dangers\")\n",
    "tokens = [token for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Λίγο ακόμη TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"Today I went driving to the grocery store. I hate to drive the car, but I love visiting the gas station!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Όλες οι λέξεις\n",
    "\n",
    "Αυτό είναι σαν το tokens, αλλά αφαιρεί τα σημεία στίξης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Today', 'I', 'went', 'driving', 'to', 'the', 'grocery', 'store', 'I', 'hate', 'to', 'drive', 'the', 'car', 'but', 'I', 'love', 'visiting', 'the', 'gas', 'station'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = TextBlob(text)\n",
    "doc.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Φράσεις με ουσιαστικά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['grocery store', 'gas station'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = TextBlob(text)\n",
    "doc.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Όλες οι προτάσεις"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Today I went driving to the grocery store.\"),\n",
       " Sentence(\"I hate to drive the car, but I love visiting the gas station!\")]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = TextBlob(text)\n",
    "doc.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 13]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(sent.words) for sent in doc.sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['I', 'went']),\n",
       " WordList(['went', 'to']),\n",
       " WordList(['to', 'the']),\n",
       " WordList(['the', 'pet']),\n",
       " WordList(['pet', 'store']),\n",
       " WordList(['store', 'to']),\n",
       " WordList(['to', 'buy']),\n",
       " WordList(['buy', 'a']),\n",
       " WordList(['a', 'fish'])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = TextBlob(\"I went to the pet store to buy a fish.\")\n",
    "doc.ngrams(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Λίστα με λέξεις"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['The', 'dangerous', 'cats', 'ran', 'dangerously', 'toward', 'dangers'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = TextBlob(\"The dangerous cats ran dangerously toward dangers.\")\n",
    "words = doc.words\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cats'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'catss'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[2].pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'catssesses'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[2].pluralize().pluralize().pluralize().pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Στελέχωση (stemming) και Λημματισμός (lemmatization) με TextBlob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:  The\n",
      "ORIGINAL:  dangerous\n",
      "ORIGINAL:  cats\n",
      "ORIGINAL:  ran\n",
      "ORIGINAL:  dangerously\n",
      "ORIGINAL:  toward\n",
      "ORIGINAL:  dangers\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"The dangerous cats ran dangerously toward dangers.\")\n",
    "words = blob.words\n",
    "\n",
    "for word in words:\n",
    "    print(\"ORIGINAL: \", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:  The | LEMMA:  The STEM:  the\n",
      "ORIGINAL:  dangerous | LEMMA:  dangerous STEM:  danger\n",
      "ORIGINAL:  cats | LEMMA:  cat STEM:  cat\n",
      "ORIGINAL:  ran | LEMMA:  ran STEM:  ran\n",
      "ORIGINAL:  dangerously | LEMMA:  dangerously STEM:  danger\n",
      "ORIGINAL:  toward | LEMMA:  toward STEM:  toward\n",
      "ORIGINAL:  dangers | LEMMA:  danger STEM:  danger\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"The dangerous cats ran dangerously toward dangers.\")\n",
    "words = blob.words\n",
    "\n",
    "for word in words:\n",
    "    print(\"ORIGINAL: \", word, \"| LEMMA: \", word.lemmatize(),\"STEM: \", word.stem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['The', 'dangerous', 'cats', 'ran', 'dangerously', 'toward', 'dangers', '.'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['The', 'dangerous', 'cats', 'ran', 'dangerously', 'toward', 'dangers'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ο λημματισμός στο TextBlob **δεν λειτουργεί καλά** Θεωρεί ότι όλα είναι ουσιαστικά, εκτός και αν του πούμε εμείς ότι δεν είναι. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"running\").words[0].lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"running\").words[0].lemmatize('v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing με το  spaCy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'dangerous', 'cat', 'run', 'dangerously', 'toward', 'danger', '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "doc = nlp(\"The dangerous cats ran dangerously toward dangers.\")\n",
    "tokens = [token.lemma_ for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Το spaCy δεν διαθέτει έτοιμο τρόπο για ανάλυση συναισθήματος, το TextBlob όμως έχει."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment for i love cars is 0.0\n",
      "The sentiment for i hate cars is 0.0\n",
      "The sentiment for i butter cars is 0.0\n",
      "The sentiment for misery and gloomy pain cars is 0.0\n"
     ]
    }
   ],
   "source": [
    "phrases = ['i love cars', 'i hate cars', 'i butter cars', 'misery and gloomy pain cars']\n",
    "for phrase in phrases:\n",
    "    doc = nlp(phrase)\n",
    "    print(\"The sentiment for\", doc, \"is\", doc[0].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment for love is Sentiment(polarity=0.5, subjectivity=0.6)\n",
      "The sentiment for hate is Sentiment(polarity=-0.8, subjectivity=0.9)\n",
      "The sentiment for butter is Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "The sentiment for misery and gloomy pain is Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "words = ['love', 'hate', 'butter', 'misery and gloomy pain']\n",
    "for word in words:\n",
    "    blob = TextBlob(word)\n",
    "    print(\"The sentiment for\", word, \"is\", blob.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Intro to scikit-learn(sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = ['i love cars', \n",
    "           'i hate cars', \n",
    "           'cars butter cars', \n",
    "           'misery and gloomy pain cars',\n",
    "           'the cars hate butter'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # VECTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Δώσε μπου κάτι που να μετρά λέξεις για μένα\n",
    "vec = CountVectorizer()\n",
    "#Έχω κάποιες προτάσεις που χρειάζονται μέτρημα\n",
    "matrix = vec.fit_transform(phrases)\n",
    "#τι βρήκες??\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 2, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 0, 1, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Το κείμενό μας έχει γίνει... VECTORIZED!!\n",
    "matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8\n",
       "0  0  0  1  0  0  1  0  0  0\n",
       "1  0  0  1  0  1  0  0  0  0\n",
       "2  0  1  2  0  0  0  0  0  0\n",
       "3  1  0  1  1  0  0  1  1  0\n",
       "4  0  1  1  0  1  0  0  0  1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'butter', 'cars', 'gloomy', 'hate', 'love', 'misery', 'pain', 'the']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = pd.DataFrame(matrix.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>butter</th>\n",
       "      <th>cars</th>\n",
       "      <th>gloomy</th>\n",
       "      <th>hate</th>\n",
       "      <th>love</th>\n",
       "      <th>misery</th>\n",
       "      <th>pain</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  butter  cars  gloomy  hate  love  misery  pain  the\n",
       "2    0       1     2       0     0     0       0     0    0\n",
       "0    0       0     1       0     0     1       0     0    0\n",
       "1    0       0     1       0     1     0       0     0    0\n",
       "3    1       0     1       1     0     0       1     1    0\n",
       "4    0       1     1       0     1     0       0     0    1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.sort_values(by='cars', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
